{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "5050\n"
     ]
    }
   ],
   "source": [
    "println(sc.parallelize(1 to 100).reduce(_ + _))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5050"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(1 to 100).reduce(_ + _)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5050\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%pyspark print sc.parallelize(range(1, 101)).reduce(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+------------------+-----------+\n",
       "|         tableName|isTemporary|\n",
       "+------------------+-----------+\n",
       "|             csvs3|      false|\n",
       "|      customeruk11|      false|\n",
       "|      customeruk12|      false|\n",
       "|    s3_differences|      false|\n",
       "|s3_differences_csv|      false|\n",
       "|              test|      false|\n",
       "|          test_csv|      false|\n",
       "|       test_csv_s3|      false|\n",
       "|     test_csv_s3_2|      false|\n",
       "|         testtable|      false|\n",
       "+------------------+-----------+\n",
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql show tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+--------------------+--------------------+\n",
       "|                 key|               value|\n",
       "+--------------------+--------------------+\n",
       "|hive.server2.thri...|                true|\n",
       "|dfs.namenode.reso...|                5000|\n",
       "|fs.s3a.connection...|                  15|\n",
       "|mapreduce.jobtrac...|                  12|\n",
       "|mapreduce.tasktra...|              600000|\n",
       "|         fs.s3a.impl|org.apache.hadoop...|\n",
       "|yarn.app.mapreduc...|                1000|\n",
       "|mapreduce.input.f...|               false|\n",
       "|hive.orc.compute....|                  10|\n",
       "|hive.auto.convert...|               false|\n",
       "+--------------------+--------------------+\n",
       "only showing top 10 rows\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+--------------------+\n",
       "|                line|\n",
       "+--------------------+\n",
       "|   # spark-appliance|\n",
       "|Distributed Spark...|\n",
       "|                    |\n",
       "|A lot of our data...|\n",
       "|                    |\n",
       "|Since we use AWS ...|\n",
       "|                    |\n",
       "|Therefore we can ...|\n",
       "|                    |\n",
       "|    ## EMRFS support|\n",
       "+--------------------+\n",
       "only showing top 10 rows\n",
       "\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select * from test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+---+\n",
       "|_c0|\n",
       "+---+\n",
       "|113|\n",
       "+---+\n",
       "\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select count(*) from test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 1.6.0 (Scala)",
   "language": "",
   "name": "spark"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
